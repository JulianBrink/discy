#!/usr/bin/env python
# coding: utf-8

# ## Scorecard writer
# Writes Pandas Dataframes (generated by another script) into an Microsoft SQL Server Database.


#system handling modules
#import os
#import sys
#import urllib

# work tools
import sqlalchemy as sqla
import pandas as pd
import pangres #used for upsert method (if used?)

#requirements for connection to microsoft sql server
#import pyodbc # not included in anaconda: pip install pyodbc

#quality of life 
#from pprint import pprint


# my own modules
import scorecard_reader as sr
import sql_reader as sqr







def write_all():
    engine = sqla.create_engine('sqlite+pysqlite:///../data/discy.db', echo=True)
    pardata = sr.create_df_pardata()
    
    
    # ## Getting the courses df to compare and upsert:
     
    # ### courses table from operational database.
    course_df_from_db = sqr.get_table_courses()
    course_df_from_pardata = pardata.loc[:,['CourseName']].rename(columns={'CourseName':'course_name'})
    course_df_from_pardata = course_df_from_pardata.drop_duplicates()
    
    # ### Concatonate/merge/join the two dataframes
    # 
    # The resulting dataframe will be used in an upsert to the operational database
    
    courses =  pd.merge(course_df_from_db,
                        course_df_from_pardata,
                        how='outer',
                        on='course_name',
                        left_on=None,
                        right_on=None,
                        left_index=False,
                        right_index=False,
                        sort=False,
                        suffixes=('_x', '_y'),
                        copy=True,
                        indicator=False,
                        validate=None)
    
    
    
    # ### upsert courses
    
    courses.set_index(['course_name'], inplace = True, drop = True)
    table_name = 'courses'
    pangres.upsert(engine, courses, table_name=table_name, if_row_exists='update')
    
    
    # ## getting the layouts df to compare and upsert
    # 
    # ### layouts table from operational database.
    
    layouts_df_from_db = sqr.get_table_layouts()
    
    layouts_df_from_pardata = pardata.loc[:,['CourseName', 'LayoutName']].drop_duplicates()
    layouts_df_from_pardata = layouts_df_from_pardata.rename(columns={'CourseName':'course_name',
                                                                      'LayoutName':'layout_name'})
    #layouts_df_from_pardata = layouts_df_from_pardata.set_index(['course_name', 'layout_name'])
    
    # ### Concatonate/merge/join the two dataframes
    # 
    # The resulting dataframe will be used in an upsert to the operational database
    # 
    layouts =  pd.merge(layouts_df_from_db,
                        layouts_df_from_pardata,
                        how='outer',
                        on=['course_name', 'layout_name'],
                        left_on=None,
                        right_on=None,
                        left_index=False,
                        right_index=False,
                        sort=False,
                        suffixes=('_x', '_y'),
                        copy=True,
                        indicator=False,
                        validate=None)
    
    
    # ### upsert layouts
    layouts.set_index(['course_name', 'layout_name'], inplace = True, drop = True)
    table_name = 'layouts'
    pangres.upsert(engine, layouts, table_name=table_name, if_row_exists='update')
    
    
    # ## getting the layout_versions df to compare and upsert
    # 
    # ### layout_versions table from operational database.
    
    layout_versions_df_from_db = sqr.get_table_layout_versions()
    
    layout_versions_df_from_pardata = pardata.iloc[:,0:6].rename(columns={pardata.columns[0]:'course_name',
                                                                           pardata.columns[1]:'layout_name',
                                                                           pardata.columns[2]:'oldest',
                                                                           pardata.columns[3]:'newest',
                                                                           pardata.columns[4]:'holes',
                                                                           pardata.columns[5]:'par'})
    
    #layout_versions_df_from_pardata = layouts_df_from_pardata.set_index(['course_name', 'layout_name'])
    layout_versions_df_from_pardata.insert(0, "version", 0)
    
    ### initial versions set on layouts_versions_from_pardata (for first time database filling)
    
    check_mults = layout_versions_df_from_pardata.loc[:,['course_name', 'layout_name']].value_counts()
    set_ones = check_mults[check_mults.values == 1]
    set_ones = set_ones.reset_index().drop(columns=[0])
    mask = layout_versions_df_from_pardata.course_name.isin(
        set_ones.course_name) & layout_versions_df_from_pardata.layout_name.isin(
        set_ones.layout_name)
    layout_versions_df_from_pardata.version = layout_versions_df_from_pardata.version.where(~mask, other=1)
    set_multiples = layout_versions_df_from_pardata.loc[layout_versions_df_from_pardata.loc[:,'version'] == 0,:]
    set_multiples = set_multiples.reset_index()
    set_multiples
    mult_counts = set_multiples.loc[:,['course_name', 'layout_name']].loc[
        set_multiples.loc[:,'version'] == 0,:].value_counts()
    mult_indices = set_multiples.groupby(['course_name', 'layout_name']).agg({'index':'min'}, axis=0)['index']
    for i in range(mult_counts.size):   
        layout_versions_df_from_pardata.iloc[mult_indices[i]:mult_indices[i]+mult_counts[i],0] = pd.Series(range(1,mult_counts[i]+1
                       ))

    # ### Concatonate/merge/join the two dataframes
    # 
    # The resulting dataframe will be used in an upsert to the operational database
    
    layout_versions =  pd.merge(layout_versions_df_from_db,
                        layout_versions_df_from_pardata,
                        how='outer',
                        on=['version', 'course_name','layout_name','oldest','newest','holes' ,'par'],
                        left_on=None,
                        right_on=None,
                        left_index=False,
                        right_index=False,
                        sort=False,
                        suffixes=('_x', '_y'),
                        copy=True,
                        indicator=False,
                        validate=None)
    
    
    
    # ## COMPARE WITH DB VERSIONS
    ## group the merged dataframe, on identical layout versions, update dates
    layout_versions = layout_versions.groupby(
        ['version', 'course_name', 'layout_name', 'holes', 'par']).agg(
        { 'oldest':'min', 'newest':'max'}, axis=0).reset_index()
    layout_versions.insert(0, "version", 0)
    ## check for number of layout versions after the grouping
    check_mults = layout_versions.loc[:,['course_name', 'layout_name']].value_counts()
    ## filter dataframe to all layouts with only one version
    set_ones = check_mults[check_mults.values == 1]
    set_ones = set_ones.reset_index().drop(columns=[0])
    
    ##use mask to set version to 1
    mask = layout_versions.course_name.isin(
        set_ones.course_name) & layout_versions.layout_name.isin(
        set_ones.layout_name)
    layout_versions.version = layout_versions.version.where(~mask, other=1)
    
    ## filter dataframe to all layouts with multiple versions
    set_multiples = layout_versions.loc[layout_versions.loc[:,'version'] == 0,:]
    set_multiples = set_multiples.reset_index()
    ## fetch count of versions for all layouts with multiple versions
    mult_counts = set_multiples.loc[:,['course_name', 'layout_name']].loc[
        set_multiples.loc[:,'version'] == 0,:].value_counts()
    ## fetch indice of first layout with multiple versions
    mult_indices = set_multiples.groupby(['course_name', 'layout_name']).agg({'index':'min'}, axis=0)['index']
    ### comparison check/update 
    
    
    
    ## overwrite "version" column on index 0 with values from 1 to n where the number of different
    
    for i in range(mult_counts.size):   
        layout_versions.iloc[mult_indices[i]:mult_indices[i]+mult_counts[i],0] = pd.Series(range(1,mult_counts[i]+1
                       ))
    layout_versions
    
    
    
    
    # ### upsert layout_versions
    
    #setting PK colums as indexes is required for upsert
    layout_versions.set_index(['version', 'course_name','layout_name'], inplace = True, drop = True)
    table_name = 'layout_versions'
    pangres.upsert(engine, layout_versions, table_name=table_name, if_row_exists='update')
    
    
    # ## getting the scoredata df to upsert
    # 
    # ### scores occuring in the scorecard at hand
    
    # ### upsert scores

if __name__ == "__main__":
    write_all()